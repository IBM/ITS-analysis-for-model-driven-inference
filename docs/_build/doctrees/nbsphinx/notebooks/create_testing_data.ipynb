{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34massets\u001b[m\u001b[m                     requirements.txt\n",
      "create_testing_data.ipynb  testing_wrapper_poisson.py\n",
      "data_creation.py           testing_wrapper_prophet.py\n",
      "its.html                   \u001b[34mwrapper\u001b[m\u001b[m\n",
      "output.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math\n",
    "!cd wrapper\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.source.prophet_model import ProphetITS\n",
    "from wrapper.source.poisson_regression import PoissonITS\n",
    "from wrapper.source.pre_processing import *\n",
    "from wrapper.source.custom_transform import CustomTransform\n",
    "from wrapper.source.wrapper_class import BaseITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The higher level classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wide Dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = ['X1']\n",
    "['X2','X3','X4']\n",
    "locations = ['Gotham']\n",
    "[ 'Neverland', 'Tomorrowland', 'Wakanda']\n",
    "interruption_dates = ['2020-04-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = pd.read_csv('wrapper/data/wide_format_data.csv')\n",
    "regions_df = dates_validation(regions_df, 'ds')\n",
    "regions_df = aggregation_wide_df_type(df=regions_df,location_col_name = 'region',date_col_name = 'ds', outcome_cols = ['X1','X2','X3','X4'])\n",
    "regions_df = regions_df.rename(columns={'region':'location'})\n",
    "# Do all the preprocessing\n",
    "# regions_df = align_prophet_naming_convection(regions_df, 'periodname','Antenatal 4th Visit')\n",
    "wrapperITS = BaseITS(model = ['prophet'], location=locations, \n",
    "                    outcome=outcomes, interruption_date=interruption_dates, verbose = False)\n",
    "# wrapperITS.fit(X = regions_df['ds'], y = regions_df['y'])\n",
    "# regions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_regions_df = regions_df[regions_df.location == 'Gotham']\n",
    "one_regions_df = one_regions_df[['ds','location','X1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapperITS.fit(one_regions_df)\n",
    "wrapperITS.predict(one_regions_df)\n",
    "wrapperITS.fit_predict(one_regions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text to stop code from running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Wrapper function for poisson Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.source.wrapper_class import BaseITS\n",
    "from wrapper.source.pre_processing import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Poisson testing - Upper Wrapper class\n",
    "outcomes = [\"X1\", \"X2\"]\n",
    "[\"X2\", \"X3\", \"X4\"]\n",
    "locations = [\"Gotham\"]\n",
    "[\"Neverland\", \"Tomorrowland\", \"Wakanda\"]\n",
    "interruption_dates = [\"2020-04-30\"]\n",
    "\n",
    "poisson_df = pd.read_csv(\"wrapper/data/poisson_testing_df.csv\")\n",
    "poisson_df = dates_validation(poisson_df, \"ds\")\n",
    "\n",
    "wrapperITS = BaseITS(\n",
    "    model=[\"poisson\"],\n",
    "    location=locations,\n",
    "    outcome=outcomes,\n",
    "    interruption_date=interruption_dates,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "one_regions_df = poisson_df[poisson_df.location == \"Gotham\"]\n",
    "one_regions_df = one_regions_df[[\"ds\", \"location\", \"X1\", \"X2\"]]\n",
    "one_regions_df\n",
    "\n",
    "# Testing fit()\n",
    "wrapperITS.fit(df=one_regions_df, X=one_regions_df[\"ds\"], y=one_regions_df[\"X1\"])\n",
    "\n",
    "# Testing predict()\n",
    "results = wrapperITS.predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[[\"X1\", \"X2\"]],\n",
    ")\n",
    "print(results)\n",
    "# Not expected to work because of Not Implemented Error\n",
    "# Testing fit_predict()\n",
    "results = wrapperITS.fit_predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[[\"X1\", \"X2\"]],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Wrapper function for prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:01:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:01:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:01:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:01:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ds                          69 non-null     datetime64[ns]\n",
      " 1   trend                       69 non-null     float64       \n",
      " 2   yhat_lower                  69 non-null     float64       \n",
      " 3   yhat_upper                  69 non-null     float64       \n",
      " 4   trend_lower                 69 non-null     float64       \n",
      " 5   trend_upper                 69 non-null     float64       \n",
      " 6   additive_terms              69 non-null     float64       \n",
      " 7   additive_terms_lower        69 non-null     float64       \n",
      " 8   additive_terms_upper        69 non-null     float64       \n",
      " 9   yearly                      69 non-null     float64       \n",
      " 10  yearly_lower                69 non-null     float64       \n",
      " 11  yearly_upper                69 non-null     float64       \n",
      " 12  multiplicative_terms        69 non-null     float64       \n",
      " 13  multiplicative_terms_lower  69 non-null     float64       \n",
      " 14  multiplicative_terms_upper  69 non-null     float64       \n",
      " 15  yhat                        69 non-null     float64       \n",
      " 16  y                           69 non-null     int64         \n",
      " 17  change                      69 non-null     float64       \n",
      " 18  percent_change              69 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1)\n",
      "memory usage: 10.4 KB\n"
     ]
    }
   ],
   "source": [
    "from wrapper.source.wrapper_class import BaseITS\n",
    "import pandas as pd\n",
    "from wrapper.source.pre_processing import *\n",
    "\n",
    "# Prophet testing - Upper Wrapper class\n",
    "outcomes = [\"X1\"]\n",
    "[\"X2\", \"X3\", \"X4\"]\n",
    "locations = [\"Gotham\"]\n",
    "[\"Neverland\", \"Tomorrowland\", \"Wakanda\"]\n",
    "interruption_dates = [\"2020-04-30\"]\n",
    "\n",
    "regions_df = pd.read_csv(\"wrapper/data/wide_format_data.csv\")\n",
    "regions_df = dates_validation(regions_df, \"ds\")\n",
    "regions_df = aggregation_wide_df_type(\n",
    "    df=regions_df,\n",
    "    location_col_name=\"region\",\n",
    "    date_col_name=\"ds\",\n",
    "    outcome_cols=[\"X1\", \"X2\", \"X3\", \"X4\"],\n",
    ")\n",
    "regions_df = regions_df.rename(columns={\"region\": \"location\"})\n",
    "# print(regions_df.columns.tolist())\n",
    "# Do all the preprocessing\n",
    "# regions_df = align_prophet_naming_convection(regions_df, 'periodname','Antenatal 4th Visit')\n",
    "wrapperITS = BaseITS(\n",
    "    model=[\"prophet\"],\n",
    "    location=locations,\n",
    "    outcome=outcomes,\n",
    "    interruption_date=interruption_dates,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "one_regions_df = regions_df[regions_df.location == \"Gotham\"]\n",
    "one_regions_df = one_regions_df[[\"ds\", \"location\", \"X1\", \"X2\"]]\n",
    "\n",
    "# Testing fit()\n",
    "wrapperITS.fit(df=one_regions_df, X=one_regions_df[\"ds\"], y=one_regions_df[\"X1\"])\n",
    "\n",
    "# Testing predict()\n",
    "results = wrapperITS.predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[\"X1\"],\n",
    ")\n",
    "\n",
    "# Testing fit_predict()\n",
    "results = wrapperITS.fit_predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[\"X1\"],\n",
    ")\n",
    "# Alter the outcome, location , dates, model columns to test multiple outputs\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:00:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:00:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:00:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:00:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got out here\n",
      "['ds', 'trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper', 'additive_terms', 'additive_terms_lower', 'additive_terms_upper', 'yearly', 'yearly_lower', 'yearly_upper', 'multiplicative_terms', 'multiplicative_terms_lower', 'multiplicative_terms_upper', 'yhat', 'y', 'change', 'percent_change']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ds                          69 non-null     datetime64[ns]\n",
      " 1   trend                       69 non-null     float64       \n",
      " 2   yhat_lower                  69 non-null     float64       \n",
      " 3   yhat_upper                  69 non-null     float64       \n",
      " 4   trend_lower                 69 non-null     float64       \n",
      " 5   trend_upper                 69 non-null     float64       \n",
      " 6   additive_terms              69 non-null     float64       \n",
      " 7   additive_terms_lower        69 non-null     float64       \n",
      " 8   additive_terms_upper        69 non-null     float64       \n",
      " 9   yearly                      69 non-null     float64       \n",
      " 10  yearly_lower                69 non-null     float64       \n",
      " 11  yearly_upper                69 non-null     float64       \n",
      " 12  multiplicative_terms        69 non-null     float64       \n",
      " 13  multiplicative_terms_lower  69 non-null     float64       \n",
      " 14  multiplicative_terms_upper  69 non-null     float64       \n",
      " 15  yhat                        69 non-null     float64       \n",
      " 16  y                           69 non-null     int64         \n",
      " 17  change                      69 non-null     float64       \n",
      " 18  percent_change              69 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1)\n",
      "memory usage: 10.4 KB\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from wrapper.source.wrapper_class import BaseITS\n",
    "from wrapper.source.prophet_model import ProphetITS\n",
    "import pandas as pd\n",
    "from wrapper.source.pre_processing import *\n",
    "\n",
    "# Prophet testing - Upper Wrapper class\n",
    "outcomes = [\"X1\"]\n",
    "[\"X2\", \"X3\", \"X4\"]\n",
    "locations = [\"Gotham\"]\n",
    "[\"Neverland\", \"Tomorrowland\", \"Wakanda\"]\n",
    "interruption_dates = [\"2020-04-30\"]\n",
    "\n",
    "regions_df = pd.read_csv(\"wrapper/data/wide_format_data.csv\")\n",
    "regions_df = dates_validation(regions_df, \"ds\")\n",
    "regions_df = aggregation_wide_df_type(\n",
    "    df=regions_df,\n",
    "    location_col_name=\"region\",\n",
    "    date_col_name=\"ds\",\n",
    "    outcome_cols=[\"X1\", \"X2\", \"X3\", \"X4\"],\n",
    ")\n",
    "regions_df = regions_df.rename(columns={\"region\": \"location\"})\n",
    "# print(regions_df.columns.tolist())\n",
    "# Do all the preprocessing\n",
    "# regions_df = align_prophet_naming_convection(regions_df, 'periodname','Antenatal 4th Visit')\n",
    "wrapperITS = BaseITS(\n",
    "    model=[\"prophet\"],\n",
    "    location=locations,\n",
    "    outcome=outcomes,\n",
    "    interruption_date=interruption_dates,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "one_regions_df = regions_df[regions_df.location == \"Gotham\"]\n",
    "one_regions_df = one_regions_df[[\"ds\", \"location\", \"X1\"]]\n",
    "\n",
    "# Testing fit()\n",
    "fitted_model = wrapperITS.fit(\n",
    "    df=one_regions_df, X=one_regions_df[\"ds\"], y=one_regions_df[\"X1\"]\n",
    ")\n",
    "# Testing predict()\n",
    "results = wrapperITS.predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[\"X1\"],\n",
    ")\n",
    "\n",
    "# print(results.values(), type(results))\n",
    "\n",
    "\n",
    "# Testing fit_predict()\n",
    "results = wrapperITS.fit_predict(\n",
    "    df=one_regions_df,\n",
    "    X=one_regions_df[\"ds\"],\n",
    "    y=one_regions_df[\"X1\"],\n",
    ")\n",
    "\n",
    "print(\"Got out here\")\n",
    "print(results.columns.tolist())\n",
    "print(results.info())\n",
    "print(isinstance(results, dict))\n",
    "# Alter the outcome, location , dates, model columns to test multiple outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ds                          69 non-null     datetime64[ns]\n",
      " 1   trend                       69 non-null     float64       \n",
      " 2   yhat_lower                  69 non-null     float64       \n",
      " 3   yhat_upper                  69 non-null     float64       \n",
      " 4   trend_lower                 69 non-null     float64       \n",
      " 5   trend_upper                 69 non-null     float64       \n",
      " 6   additive_terms              69 non-null     float64       \n",
      " 7   additive_terms_lower        69 non-null     float64       \n",
      " 8   additive_terms_upper        69 non-null     float64       \n",
      " 9   yearly                      69 non-null     float64       \n",
      " 10  yearly_lower                69 non-null     float64       \n",
      " 11  yearly_upper                69 non-null     float64       \n",
      " 12  multiplicative_terms        69 non-null     float64       \n",
      " 13  multiplicative_terms_lower  69 non-null     float64       \n",
      " 14  multiplicative_terms_upper  69 non-null     float64       \n",
      " 15  yhat                        69 non-null     float64       \n",
      " 16  y                           69 non-null     int64         \n",
      " 17  change                      69 non-null     float64       \n",
      " 18  percent_change              69 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1)\n",
      "memory usage: 10.4 KB\n"
     ]
    }
   ],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ds                          69 non-null     object \n",
      " 1   trend                       69 non-null     float64\n",
      " 2   yhat_lower                  69 non-null     float64\n",
      " 3   yhat_upper                  69 non-null     float64\n",
      " 4   trend_lower                 69 non-null     float64\n",
      " 5   trend_upper                 69 non-null     float64\n",
      " 6   additive_terms              69 non-null     float64\n",
      " 7   additive_terms_lower        69 non-null     float64\n",
      " 8   additive_terms_upper        69 non-null     float64\n",
      " 9   yearly                      69 non-null     float64\n",
      " 10  yearly_lower                69 non-null     float64\n",
      " 11  yearly_upper                69 non-null     float64\n",
      " 12  multiplicative_terms        69 non-null     float64\n",
      " 13  multiplicative_terms_lower  69 non-null     float64\n",
      " 14  multiplicative_terms_upper  69 non-null     float64\n",
      " 15  yhat                        69 non-null     float64\n",
      " 16  y                           69 non-null     int64  \n",
      " 17  change                      69 non-null     float64\n",
      " 18  percent_change              69 non-null     float64\n",
      "dtypes: float64(17), int64(1), object(1)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(results).to_csv(\"wrapper/data/metrics.csv\",index=False)\n",
    "pd.read_csv(\"wrapper/data/metrics.csv\").info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted models with one location & one outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_once_prophet_model = wrapperITS.fit_once(regions_df['ds'],regions_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapperITS.fit(regions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if (aggregation_wide_df_type(df=regions_df,location_col_name = 'Region',date_col_name = 'periodname', outcome_cols = [\"Antenatal 4th Visit\", \"Deliveries\", \"New\"])).shape[0] == regions_df.shape[0]:\n",
    "    print(\"Data already aggregated\")\n",
    "else:\n",
    "    print('Data not aggregated yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wrapper/data/ugandaHealthfacility.csv\")\n",
    "df = aggregation_long_df_type(df=df,location_col_name='region',date_col_name='ds',\n",
    "                                outcome_col_name='outcome',outcome_value_col_name='value')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_region (row):\n",
    "    if row['organisationunitname'] in South_South:\n",
    "        return 'South South'\n",
    "    if row['organisationunitname'] in South_West:\n",
    "        return 'South West'\n",
    "    if row['organisationunitname'] in South_East:\n",
    "        return 'South East'\n",
    "    if row['organisationunitname'] in North_Central:\n",
    "        return 'North Central'\n",
    "    if row['organisationunitname'] in North_East:\n",
    "        return 'North East'\n",
    "    if row['organisationunitname'] in North_West:\n",
    "        return 'North West'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "South_South = [\"ak Akwa-Ibom State\",\"by Bayelsa State\",\"cr Cross River State\",\"de Delta State\",\"ed Edo State\",\"ri Rivers State\"] \n",
    "South_East = [\"ab Abia State\",\" an Anambra state\",\"eb Ebonyi State\",\"en Enugu State\",\"im Imo State\"]\n",
    "South_West = [\"ek Ekiti State\",\"la Lagos State\",\"og Ogun State\",\"on Ondo State\",\"os Osun State\",\"oy Oyo State\"]\n",
    "\n",
    "North_East = [\"ad Adamawa State\",\"ba Bauchi State\",\"bo Borno State\",\"go Gombe State\",\"ta Taraba State\",\"yo Yobe State\"]\n",
    "North_West = [\"ji Jigawa State\",\"kd Kaduna State\",\"kn Kano State\",\"kt Katsina State\",\"ke Kebbi State\",\"so Sokoto State\",\"za Zamfara State\"]\n",
    "North_Central = [\"be Benue State\",\"ko Kogi State\",\"kw Kwara State\",\"na Nasarawa State\",\"ni Niger State\",\"pl Plateau State\",\"fc Federal Capital Territory\"]\n",
    "\n",
    "df_copy = df_new.groupby(['organisationunitname','periodname'])['Antenatal 4th Visit'].sum().reset_index()\n",
    "df_copy['Region'] = df_copy.apply(label_region, axis = 1)\n",
    "\n",
    "df_copy.to_csv('wrapper/data/anc_visits_regions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   location  276 non-null    object        \n",
      " 1   ds        276 non-null    datetime64[ns]\n",
      " 2   y         276 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"wrapper/data/prophet_testing_df.csv\")\n",
    "test_dataset = dates_validation(test_dataset, \"ds\")\n",
    "test_dataset = align_prophet_naming_convection(test_dataset, 'ds', \"X1\")\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:47:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:47:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ds                          276 non-null    datetime64[ns]\n",
      " 1   trend                       276 non-null    float64       \n",
      " 2   yhat_lower                  276 non-null    float64       \n",
      " 3   yhat_upper                  276 non-null    float64       \n",
      " 4   trend_lower                 276 non-null    float64       \n",
      " 5   trend_upper                 276 non-null    float64       \n",
      " 6   additive_terms              276 non-null    float64       \n",
      " 7   additive_terms_lower        276 non-null    float64       \n",
      " 8   additive_terms_upper        276 non-null    float64       \n",
      " 9   yearly                      276 non-null    float64       \n",
      " 10  yearly_lower                276 non-null    float64       \n",
      " 11  yearly_upper                276 non-null    float64       \n",
      " 12  multiplicative_terms        276 non-null    float64       \n",
      " 13  multiplicative_terms_lower  276 non-null    float64       \n",
      " 14  multiplicative_terms_upper  276 non-null    float64       \n",
      " 15  yhat                        276 non-null    float64       \n",
      " 16  y                           276 non-null    int64         \n",
      " 17  change                      276 non-null    float64       \n",
      " 18  percent_change              276 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1)\n",
      "memory usage: 41.1 KB\n"
     ]
    }
   ],
   "source": [
    "prediction_start_date = datetime.strptime('2020-04-30', '%Y-%m-%d')\n",
    "prophet = ProphetITS()\n",
    "training_df = test_dataset[test_dataset['ds'] <= prediction_start_date ]\n",
    "prophet.fit(training_df)\n",
    "results = prophet.predict(test_dataset)\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Implementation coming soon. Not implemented in the base prophet class used.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_df = pd.read_csv(\"wrapper/data/poisson_testing_df.csv\")\n",
    "# poisson_df = poisson_df[['ds','time','pop','time','region','Diabetes','pandemic_april','month']]\n",
    "# poisson_df = poisson_df.loc[poisson_df['region'] == 'Central Region']\n",
    "poisson_df = dates_validation(poisson_df,'ds')\n",
    "poisson_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CustomTransform(columns = ['pandemic_april','time'], seasonally_adjusted = True, var_name='month') \n",
    "X = transform.transform(poisson_df)  \n",
    "y = poisson_df['X1'] \n",
    "offset = np.log(poisson_df['pop'])  \n",
    "poisson_model = PoissonITS()\n",
    "poisson_model.fit(X, y, offset)  \n",
    "c = poisson_model.summary()\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_df.to_csv(\"wrapper/data/poisson_testing_df.csv\",index=False)\n",
    "prediction_start_date = datetime.strptime('2020-04-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 100000\n",
    "pred_df = poisson_df.copy()\n",
    "pred_df['y'] = pred_df['Diabetes']/pred_df['pop']\n",
    "X_pred = transform.transform(pred_df)\n",
    "X_pred['pandemic_april'] = 0\n",
    "y_pred = poisson_model.predict(X_pred, pred_df)\n",
    "forecast = pd.concat([pred_df[['ds','y']], y_pred], axis = 1)\n",
    "forecast.columns.tolist()\n",
    "\n",
    "# forecast['change'] = forecast['y'] - forecast['yhat']\n",
    "# forecast['percent_change'] = forecast.apply(lambda row: round((row.y - row.yhat)/row.yhat *100,2), axis =1)\n",
    "# forecast[['y', 'yhat', 'yhat_lower', 'yhat_upper', 'change']] = forecast[['y', 'yhat', 'yhat_lower', 'yhat_upper', 'change']]*factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model.fit_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.wrapper': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c981f8d8cd2aec6fd8a1f58b72fefeda2323239c142ab1df7535f492457cacb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
